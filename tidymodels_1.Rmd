---
title: "Influenza Project - TidyModels Analysis (Part 1)"
output: 
  html_document:
    theme: flatly
    toc: FALSE
---
<br>

## Introduction
This exercise focuses on applying the base TidyModels framework to the influenza data, and most of the code comes from the [TidyModels' "Build a Model" Tutorial](https://www.tidymodels.org/start/models/).

<br>

The raw data for this exercise comes from the following citation:
McKay, Brian et al. (2020), Virulence-mediated infectiousness and activity trade-offs and their impact on transmission potential of patients infected with influenza, Dryad, Dataset, https://doi.org/10.5061/dryad.51c59zw4v.

The processed data was produced on the `Data Processing` page.

<br>

Within this analysis, the following definitions exist:

* Main predictor of interest = Runny Nose
* Continuous outcome of interest = Body Temperature
* Categorical outcome of interest = Nausea
* Whichever outcome is not currently fitted will be considered a predictor of interest
* All variables are included (even when there are multiple variables for the same symptom)

<br>

The overall steps of this exercise are as follows:

1. Load the processed data
2. Fit a linear model to the continuous outcome using only the main predictor of interest
3. Fit another linear model to the continuous outcome using all predictors of interest
4. Compare model results for models created in steps (2) and (3)
5. Fit a logistic model to the categorical outcome using only the main predictor of interest
6. Fit another logistic model to the categorical outcome using all predictors of interest
7. Compare model results for models created in steps (5) and (6)

---

## Required Packages
The following R packages are required for this exercise:

* here: for path setting
* tidyverse: for all packages in the Tidyverse (ggplot2, dyplr, tidyr, readr, purr, tibble, stringr, forcats)
* summarytools: for overall dataframe summary
* ggplot2: for plotting data
* tidymodels: for all packages in the TidyModels suite
* broom.mixed: for converting bayesian models to tidy tibbles
* broom: for model organization / clarity
* dotwhisker: for visualizing regression results
* gtsummary: for converting regression results to table
* modelsummary: for comparing results of models
* flextable: for exporting tables

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(here) #for data loading/saving
library(summarytools) #to create overall dataframe summary
library(tidyverse) #for all packages in the tidyverse
library(ggplot2) #for data visualization and plotting
library(tidymodels) #for the tidymodels suite
library(broom.mixed) #for converting bayesian models to tidy tibbles
library(broom) #for model organization / clarity
library(dotwhisker) # for visualizing regression results
library(gtsummary) #for converting regression results to table
library(modelsummary) #to compare results of models
library(flextable) #for exporting tables
```

---

## Load Processed Data
Load the data created on the `Data Processing` page.
```{r}
# path to data
# note the use of the here() package and not absolute paths
data_location <- here::here("data","flu","processeddata.rds")

# load data using the "ReadRDS" function in base R.
mydata <- base::readRDS(data_location)
```

---

## Data Summary
For a more robust exploration, refer to the `Exploratory Data Analysis` page. However, for reference, we can look at the dataframe summary using the `skimr` package.
```{r}
#summary of data using skimr package
skimr::skim(mydata)
```

---

## Linear Model for Body Temperature with Runny Nose
The first linear model to create is a simple one using the continuous outcome of interest (BodyTemp) and main predictor of interest (RunnyNose). Using the parsnip package, specify the functional form of the model (linear regression) and method for fitting the model, aka engine ("lm").
```{r}
#save the model object as lm_mod
lm_mod <-
  parsnip::linear_reg() %>%
  parsnip::set_engine("lm")
```

<br>

Now estimate the model using the fit function and summarize the linear model.
```{r}
lm_fit1 <- lm_mod %>%
              fit(BodyTemp ~ RunnyNose, data = mydata)

#summarize linear model
lm_fit1_summary <- broom.mixed::tidy(lm_fit1)
lm_fit1_summary
```
The intercept estimate (no runny nose) is 99.1F, which would make these patients febrile. We can interpret the slope estimate as: Patients with a runny nose on average have a 0.293F lower body temperature than patients without a runny nose.

<br>

Next, we can create a box and whisker plot for lm_fit1 output.
```{r}
lm_fit1_bp <- broom.mixed::tidy(lm_fit1) %>%
                dotwhisker::dwplot(dot_args = list(size = 2, color = "blue"),
                                   whisker_args = list(color = "blue"),
                                   vline = geom_vline(xintercept = 0, colour = "grey50", linetype = 2))
lm_fit1_bp
```
This shows us the estimate is significant (i.e. doesn't cross the null hypothesis), and runny nose is a protective factor against increased body temperature.

<br>

Last, we can use the glance function to examine goodness of fit measures.
```{r}
lm_fit1_gf <- modelsummary::glance(lm_fit1)
lm_fit1_gf
```
This model has an extremely low R^2, high AIC, BIC.

---

## Linear Model for Body Temperature with All Predictors
The second linear model to create includes all variables in the dataset as predictors with the main outcome of interest as BodyTemp. We can use the same lm_mod function, so no need to respecify.
```{r}
#create model including all predictors (defined using the . instead of specifying all variable names)
#doesn't include interaction terms
lm_fit2 <- lm_mod %>%
              fit(BodyTemp ~ ., data = mydata)
```

<br>

Now we can summarize the full linear model
```{r}
#add print function to show all rows
lm_fit2_summary <- print(broom.mixed::tidy(lm_fit2), n = 38)
lm_fit2_summary
#the NA lines are where all patients are reporting the symptom (so no comparison possibility)

#export results into a table using the gtsummary package
gtsummary::tbl_regression(lm_fit2)
```
Within this fit, significant predictors at alpha = 0.05 are Sneeze, SubjectiveFever, & Pharyngitis.

<br>

Now we can create a box and whisker plot for lm_fit2 output.
```{r}
lm_fit2_bp1 <- broom.mixed::tidy(lm_fit2) %>%
                dotwhisker::dwplot(dot_args = list(size = 2, color = "blue"),
                                   whisker_args = list(color = "blue"),
                                   vline = geom_vline(xintercept = 0, colour = "grey50", linetype = 2))
lm_fit2_bp1
#there's a lot of information here, but hard to identify the ones that are significant due to volume

#box and whisker plot for lm_fit2 significant predictors
#first filter significant results
lm_fit2_sig <- broom.mixed::tidy(lm_fit2) %>%
                  dplyr::filter(p.value < 0.05)

#box and whisker plot for lm_fit2 significant predictors
lm_fit2_bp2 <- lm_fit2_sig %>%
                  dotwhisker::dwplot(dot_args = list(size = 2, color = "blue"),
                                     whisker_args = list(color = "blue"),
                                     vline = geom_vline(xintercept = 0, colour = "grey50", linetype = 2))
lm_fit2_bp2
```

<br>

Last, we can use the glance function to examine goodness of fit measures
```{r}
lm_fit2_gf <- modelsummary::glance(lm_fit2)
lm_fit2_gf
```
In comparison to lm_fit1, this model has an increased R^2, slightly lower AIC, BIC, but we need the formal comparison to better understand the significance.

---

## Compare the Linear Regression Models
First, we want to combine results of the two models into one table.
```{r}
#create a list of the two models
lm_models <- list(lm_fit1, lm_fit2)

#using the model summary package
#list estimate, 95% confidence intervals, and highlight ones with significant p-values
#hide intercept estimate
modelsummary::modelsummary(lm_models, 
                           stars = TRUE, 
                           fmt = '%.3f',
                           estimate  = "{estimate} [{conf.low}, {conf.high}] {stars}",
                           statistic = NULL,
                           coef_omit = "Intercept")
```
In this comparison, we can see the significance of the runny nose estimate decreases, the runny nose Beta estimate gets closer to zero. Moreover, in comparison to lm_fit1, lm_fit2 has increased R^2, slightly lower AIC, BIC, log likelihood.

<br>

Next, we can conduct an ANOVA to formally compare the two linear regression models
```{r}
lm_anova <- anova(lm_fit1$fit, lm_fit2$fit, test = "Chisq")
lm_anova
```
Based on the p-value from the ANOVA, we can conclude the more complex model better describes the data than the SLR. This is also supported by the comparison of AIC and BIC above.

---

## Logistic Model for Nausea with Runny Nose
The next model to create is a simple one using the categorical outcome of interest (Nausea) and main predictor of interest (RunnyNose). Using the parsnip package, specify the functional form of the model (logistic regression) and method for fitting the model, aka engine ("glm")
```{r}
#save the model object as log_mod
log_mod <-
  parsnip::logistic_reg() %>%
  parsnip::set_engine("glm")
```

<br>

We can now estimate the model using the fit function.
```{r}
log_fit1 <- log_mod %>%
  fit(Nausea ~ RunnyNose, data = mydata)
```

<br>

Next, we can summarize logistic model with the tidy function. However, we want to exponentiate estimates to make them interpretable odds ratios.
```{r}
log_fit1_summary <- broom.mixed::tidy(log_fit1, exponentiate = TRUE)
log_fit1_summary
```
This does not yield a significant estimate (p > 0.05).

<br>

Now, we can create a box and whisker plot for log_fit1 output.
```{r}
log_fit1_bp <- broom.mixed::tidy(log_fit1) %>%
                dotwhisker::dwplot(dot_args = list(size = 2, color = "blue"),
                                   whisker_args = list(color = "blue"),
                                   vline = geom_vline(xintercept = 0, colour = "grey50", linetype = 2))
log_fit1_bp
```
This doesn't really mean much since we only have one category beyond not significant results.

<br>

Lastly, we can use the glance function to examine goodness of fit measures.
```{r}
log_fit1_gf <-modelsummary::glance(log_fit1)
log_fit1_gf 
```
We can see this fit has a lower AIC, BIC, loglikelihood than linear model. This is obviously not a direct comparison but still an interesting result.

---

## Logistic Model for Nausea with All Predictors
The second logistic model to create includes all variables in the dataset as predictors with the main outcome of interest as Nausea. We can use the same log_mod function, so no need to respecify. We first want to create model including all predictors (defined using the . instead of specifying all variable names).
```{r}
#doesn't include interaction terms
log_fit2 <- log_mod %>%
  fit(Nausea ~ ., data = mydata)
```

<br>

Next, we can summarize logistic model with the tidy function. However, we want to exponentiate estimates to make them interpretable odds ratios.
```{r}
#adding the print function to see all rows
log_fit2_summary <- print(broom.mixed::tidy(log_fit2, exponentiate = TRUE), n = 38)
log_fit2_summary
#the NA lines are where all patients are reporting the symptom (so no comparison possibility)

#export results into a table using the gtsummary package
log_fit2_gtsummary <- gtsummary::tbl_regression(log_fit2, exponentiate = TRUE)
log_fit2_gtsummary
```
In this model, the significant predictors at alpha = 0.05 are AbPain, Diarrhea, Breathless, ToothPn, and Vomit. Vomit and Diarrhea makes sense as they often co-present with nausea, and abdominal pain as well as breathlessness make clinical sense. Tooth pain is a surprising result.

<br>

Now we can create a box and whisker plot for log_fit2 output.
```{r}
log_fit2_bp1 <- broom.mixed::tidy(log_fit2) %>%
                  dotwhisker::dwplot(dot_args = list(size = 2, color = "blue"),
                                     whisker_args = list(color = "blue"),
                                     vline = geom_vline(xintercept = 0, colour = "grey50", linetype = 2))
log_fit2_bp1
#there's a lot of information here, but hard to identify the ones that are significant due to volume

#box and whisker plot for log_fit2 significant predictors
#first filter significant results
log_fit2_sig <- broom.mixed::tidy(log_fit2) %>%
  dplyr::filter(p.value < 0.05)

#box and whisker plot for log_fit2 significant predictors
log_fit2_bp2 <- log_fit2_sig %>%
                  dotwhisker::dwplot(dot_args = list(size = 2, color = "blue"),
                                     whisker_args = list(color = "blue"),
                                     vline = geom_vline(xintercept = 0, colour = "grey50", linetype = 2))
log_fit2_bp2
```
All significant predictors in this model increase odds of having nausea. It makes sense vomit and diarrhea have the highest OR, given the frequent co-presentation of the three symptoms.

<br>

Lastly, we can use the glance function to examine goodness of fit measures.
```{r}
log_fit2_gf <- modelsummary::glance(log_fit2)
log_fit2_gf
```
In comparison to log_fit1, this model has a lower log likelihood, AIC, BIC, deviance, but we need the formal comparison to better understand the significance.

---

## Compare the Logistic Regression Models
First, we need to combine results of the two models into one table.
```{r}
log_models <- list(log_fit1, log_fit2)

#list estimate, 95% confidence intervals, and highlight ones with significant p-values
#hide intercept estimate
modelsummary::modelsummary(log_models, 
                           stars = TRUE, 
                           fmt = '%.3f', 
                           exponentiate = TRUE,
                           estimate  = "{estimate} [{conf.low}, {conf.high}] {stars}",
                           statistic = NULL,
                           coef_omit = "Intercept")
```
Interestingly, runny nose is not a significant predictor in either model. In comparison to log_fit1, log_fit2 has a slightly lower AIC and log likelihood, but higher BIC.

<br>

Next, we can conduct an ANOVA to compare the two linear regression models
```{r}
log_anova <- anova(log_fit1$fit, log_fit2$fit, test = "Chisq")
log_anova
```
Based on the p-value from the ANOVA, we can conclude the more complex model better describes the data than the simple logistic regression, which is also supported by the comparison of measures above. However, the higher BIC suggests the significance noted may be a result from the number of parameters included in the model. In a real-world analysis, we would need to examine the potential of overfitting occurring in the full logistic regression model.