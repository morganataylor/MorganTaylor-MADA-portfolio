---
title: "Influenza Project - Data Processing"
output: 
  html_document:
    theme: flatly
    toc: FALSE
---
<br>

## Introduction
This exercise focuses on loading the raw data and cleaning/processing it for further analysis.

The raw data for this exercise comes from the following citation:
McKay, Brian et al. (2020), Virulence-mediated infectiousness and activity trade-offs and their impact on transmission potential of patients infected with influenza, Dryad, Dataset, https://doi.org/10.5061/dryad.51c59zw4v.

---

## Required Packages
The following R packages are required for this exercise:

* here: for path setting
* tidyverse: for all packages in the Tidyverse (ggplot2, dyplr, tidyr, readr, purr, tibble, stringr, forcats)
* skimr: for data summarization
```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)

#load required packages
library(here) #to set paths
library(dplyr) #for data processing
library(skimr) #for data summarization
```

---

## Load Raw Data
Load the raw data downloaded from provided DOI link.
```{r}
#path to data
#note the use of the here() package and not absolute paths
data_location <- here::here("data","flu","SympAct_Any_Pos.Rda")

#load data. 
#because the data is in an .Rda format, we can use the "ReadRDS" function in base R.
#the typical "load" function does not work (data is RDS not RDA)
rawdata <- base::readRDS(data_location)

#take a look at the data
dplyr::glimpse(rawdata)
```

---

## Overall Processing
The first step is to conduct some over all processing to create a dataset to be used in most of the analysis:

* Remove all variables that have `Score` or `Total` or `FluA` or `FluB` or `Dxname` or `Activity` in the name
* Remove `Unique.Visit`
* Remove any `NA` observations
```{r}
#this can be accomplished using the select function in dplyr / tidyverse

#while we could pipe this into one operation, separating each line makes de-bugging issues easier

#remove variables containing "Score"
data1 <- rawdata %>% dplyr::select(-contains("Score"))

#remove variables containing "Total"
data2 <- data1 %>% dplyr::select(-contains("Total"))

#remove variables containing "FluA"
data3 <- data2 %>% dplyr::select(-contains("FluA"))

#remove variables containing "FluB"
data4 <- data3 %>% dplyr::select(-contains("FluB"))

#remove variables containing "Dxname"
data5 <- data4 %>% dplyr::select(-contains("Dxname"))

#remove variables containing "Activity"
data6 <- data5 %>% dplyr::select(-contains("Activity"))

#remove variable "Unique.Visit"
data7 <- data6 %>% dplyr::select(-contains("Unique.Visit"))

#check to make sure we have the correct columns remaining
dplyr::glimpse(data7)
base::summary(data7)

#last step is to remove any NA observations
processed_data <- stats::na.omit(data7)

#summary of processed data using skimr package
skimr::skim(processed_data)
```
We now have a newly processed dataframe with 730 observations and 32 variables, which is our goal.
---

## Machine Learning Processing
The analysis that applies machine learning models requires data that is further processed. There are two steps involved:

* Feature removal
* Address low ("near-zero") variance predictors

<br>

### Feature Variable Removal
In the output above, there are three variables that have both a severity score and a yes/no feature: weakness, cough, and myalgia. There are actually two variables for cough yes/no. These variables are strongly correlated and therefore affect model performance. Solution: remove all yes/no versions of variables for which a severity score exists.
```{r}
#variable names to remove: WeaknessYN, MyalgiaYN, CoughYN, CoughYN2
featadj_data <- dplyr::select(processed_data, -c(WeaknessYN, MyalgiaYN, CoughYN, CoughYN2))
```

These severity scores are also ordered, so we need to specify the order: None < Mild < Moderate < Severe.
```{r}
#myalgia
featadj_data$Myalgia <- ordered(featadj_data$Myalgia, labels = c("None", "Mild", "Moderate", "Severe"))

#weakness
featadj_data$Weakness <- ordered(featadj_data$Weakness, labels = c("None", "Mild", "Moderate", "Severe"))

#cough
featadj_data$CoughIntensity <- ordered(featadj_data$CoughIntensity, labels = c("None", "Mild", "Moderate", "Severe"))

#double check to confirm code worked
skimr::skim(featadj_data)
```

<br>

### Low ("near-zero") variance predictors
The skimr output shows there are some predictors that are fairly unbalanced with most patients reporting `no` and only a few `yes`. This can be handled automatically in `tidymodels` with `step_nzv()`, but it can be better to do it manually to ensure scientific relevance. Here, we will remove binary predictors that have <50 entries in one category. According to the `skimr::skim` output, there are two: `Hearing` and `Vision`.
```{r}
#drop Hearing and Vision from the dataset to create processed dataset for ML analysis
ML_processed <- dplyr::select(featadj_data, -c(Hearing, Vision))

#summary of data using skimr package
skimr::skim(ML_processed)
```
We now have a newly processed dataframe with 730 observations and 26 variables to be used for the machine learning analysis.

---

## Save Processed Data
Save the processed data to be referenced in subsequent analyses.
```{r}
#for the overall processed data:
# location to save file
save_data_location <- here::here("data","flu","processeddata.rds")

# save data as RDS
saveRDS(processed_data, file = save_data_location)

#for the machine learning processed data:
# location to save file
save_data_location2 <- here::here("data","flu","ML_data.rds")

# save data as RDS
saveRDS(ML_processed, file = save_data_location2)
```
